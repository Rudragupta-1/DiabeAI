{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rudragupta-1/DiabeAI/blob/main/DiabAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhw7mO6apjEf"
      },
      "outputs": [],
      "source": [
        "# Diabetes Prediction Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, roc_curve\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BXEWCFjsqoly",
        "outputId": "5b1cd55b-0a59-4b62-f0cb-2ffd9179cd49"
      },
      "outputs": [],
      "source": [
        "# Step 2: Load the Dataset\n",
        "df = pd.read_csv('/diabetes_prediction_dataset.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "r7MViR0ir3ss",
        "outputId": "80c8a954-e596-4e31-8d7c-405ca3e505c3"
      },
      "outputs": [],
      "source": [
        "# Step 3: Exploratory Data Analysis (EDA)\n",
        "\n",
        "# Encode categorical columns using LabelEncoder for simplicity since they are binary\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create a LabelEncoder instance\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encoding 'gender' and 'smoking' (converting 'Male'/'Female' to 0/1 and 'Yes'/'No' to 0/1)\n",
        "df['gender'] = label_encoder.fit_transform(df['gender'])\n",
        "df['smoking_history'] = label_encoder.fit_transform(df['smoking_history'])\n",
        "\n",
        "# Check if encoding was successful\n",
        "print(df[['gender', 'smoking_history']].head())\n",
        "\n",
        "# Correlation Heatmap to understand feature relationships\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MUVOqCkgr65A"
      },
      "outputs": [],
      "source": [
        "# Step 4: Data Preprocessing\n",
        "\n",
        "# Categorical and numerical columns separation\n",
        "categorical_cols = ['gender', 'smoking_history']  # Assuming these are the only categorical features\n",
        "numerical_cols = ['age', 'hypertension', 'heart_disease', 'bmi', 'HbA1c_level', 'blood_glucose_level']\n",
        "\n",
        "# Preprocessing for numerical data: Imputation (median) + Scaling\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Preprocessing for categorical data: Imputation (most frequent) + One-Hot Encoding\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(drop='first'))  # Avoid dummy variable trap\n",
        "])\n",
        "\n",
        "# Combining preprocessing steps for numerical and categorical columns\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CP-PF17Nr96r"
      },
      "outputs": [],
      "source": [
        "# Step 5: Splitting Data into Training and Testing sets\n",
        "\n",
        "X = df.drop(columns=['diabetes'])  # Features\n",
        "y = df['diabetes']  # Target variable\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VltOMOMbsBr6"
      },
      "outputs": [],
      "source": [
        "# Step 6: Model Training using Pipelines\n",
        "\n",
        "# Pipeline for Logistic Regression\n",
        "log_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', LogisticRegression(random_state=42))\n",
        "])\n",
        "\n",
        "# Pipeline for Random Forest Classifier\n",
        "rf_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', RandomForestClassifier(random_state=42))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db0XToaUsDhV",
        "outputId": "4252e30e-7db0-4d07-9b71-4d4ee09b284a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 7: Hyperparameter Tuning and Cross-Validation\n",
        "\n",
        "# Random Forest Hyperparameters tuning using GridSearchCV\n",
        "param_grid = {\n",
        "    'model__n_estimators': [50, 100, 200],\n",
        "    'model__max_depth': [None, 10, 20, 30],\n",
        "    'model__min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_search_rf = GridSearchCV(rf_pipeline, param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best Parameters for Random Forest: {grid_search_rf.best_params_}\")\n",
        "best_rf_model = grid_search_rf.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9xHpY2PysHRp",
        "outputId": "de82708a-c310-4d67-c4c6-cd210bfcc900"
      },
      "outputs": [],
      "source": [
        "# Step 8: Model Evaluation\n",
        "\n",
        "# Logistic Regression Evaluation\n",
        "log_pipeline.fit(X_train, y_train)\n",
        "y_pred_log = log_pipeline.predict(X_test)\n",
        "\n",
        "print(\"Logistic Regression Model Performance:\")\n",
        "print(confusion_matrix(y_test, y_pred_log))\n",
        "print(classification_report(y_test, y_pred_log))\n",
        "print(f\"ROC-AUC Score: {roc_auc_score(y_test, log_pipeline.predict_proba(X_test)[:, 1])}\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_log)}\")\n",
        "\n",
        "# Random Forest Evaluation (with tuned hyperparameters)\n",
        "y_pred_rf = best_rf_model.predict(X_test)\n",
        "\n",
        "print(\"Random Forest Model Performance:\")\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print(f\"ROC-AUC Score: {roc_auc_score(y_test, best_rf_model.predict_proba(X_test)[:, 1])}\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf)}\")\n",
        "\n",
        "# ROC Curve for both models\n",
        "y_pred_log_proba = log_pipeline.predict_proba(X_test)[:, 1]\n",
        "y_pred_rf_proba = best_rf_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "fpr_log, tpr_log, _ = roc_curve(y_test, y_pred_log_proba)\n",
        "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf_proba)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr_log, tpr_log, label='Logistic Regression (AUC = {:.2f})'.format(roc_auc_score(y_test, y_pred_log_proba)))\n",
        "plt.plot(fpr_rf, tpr_rf, label='Random Forest (AUC = {:.2f})'.format(roc_auc_score(y_test, y_pred_rf_proba)))\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A1SdAFgsKBB",
        "outputId": "54822553-7305-4df2-f7d8-0fe3c738c2e1"
      },
      "outputs": [],
      "source": [
        "# Step 9: Save the Best Model\n",
        "\n",
        "# Saving the Random Forest Model (Assuming it performs better)\n",
        "joblib.dump(best_rf_model, 'diabetes_prediction_model.pkl')\n",
        "print(\"Random Forest Model saved successfully!\")\n",
        "\n",
        "# Step 10: Load the Model for Future Predictions\n",
        "# To load the model, you can use:\n",
        "# loaded_model = joblib.load('diabetes_prediction_model.pkl')\n",
        "# predictions = loaded_model.predict(new_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9UXYLprysjm",
        "outputId": "92b4a155-e1ff-49b4-8110-ada075fc0dc5"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fgb54RM-x3yc",
        "outputId": "4d2cf403-13dd-49ce-af56-c1302fbf165b"
      },
      "outputs": [],
      "source": [
        "# Save your trained model (assuming it's the Random Forest model)\n",
        "joblib.dump(best_rf_model, 'diabetes_prediction_model.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnMAOV-gx4mb",
        "outputId": "42a856cc-c13f-403f-f902-9baf13119d4e"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model\n",
        "model = joblib.load('diabetes_prediction_model.pkl')\n",
        "\n",
        "# Function to predict diabetes\n",
        "def predict_diabetes(gender, age, hypertension, heart_disease, smoking, bmi, hba1c, blood_glucose):\n",
        "    # Encode categorical variables\n",
        "    gender = 1 if gender == 'Female' else 0\n",
        "    smoking = 1 if smoking == 'Yes' else 0\n",
        "\n",
        "    # Prepare the input data as a DataFrame\n",
        "    input_data = pd.DataFrame({\n",
        "        'gender': [gender],\n",
        "        'age': [age],\n",
        "        'hypertension': [hypertension],\n",
        "        'heart_disease': [heart_disease],\n",
        "        'smoking': [smoking],\n",
        "        'bmi': [bmi],\n",
        "        'HbA1c_level': [hba1c],\n",
        "        'blood_glucose_level': [blood_glucose]\n",
        "    })\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(input_data)\n",
        "    return prediction[0]\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"Diabetes Prediction App\")\n",
        "st.header(\"Enter Patient Information\")\n",
        "\n",
        "# User input fields\n",
        "gender = st.selectbox(\"Gender\", options=[\"Male\", \"Female\"])\n",
        "age = st.number_input(\"Age\", min_value=0, max_value=120, value=30)\n",
        "hypertension = st.selectbox(\"Hypertension (0 = No, 1 = Yes)\", options=[0, 1])\n",
        "heart_disease = st.selectbox(\"Heart Disease (0 = No, 1 = Yes)\", options=[0, 1])\n",
        "smoking = st.selectbox(\"Smoking (Yes/No)\", options=[\"Yes\", \"No\"])\n",
        "bmi = st.number_input(\"BMI\", min_value=10.0, max_value=50.0, value=25.0)\n",
        "hba1c = st.number_input(\"HbA1c Level (%)\", min_value=0.0, max_value=15.0, value=5.0)\n",
        "blood_glucose = st.number_input(\"Blood Glucose Level (mg/dL)\", min_value=0.0, max_value=500.0, value=100.0)\n",
        "\n",
        "# Prediction button\n",
        "if st.button(\"Predict\"):\n",
        "    prediction = predict_diabetes(gender, age, hypertension, heart_disease, smoking, bmi, hba1c, blood_glucose)\n",
        "    if prediction == 1:\n",
        "        st.success(\"The model predicts that the patient **has diabetes**.\")\n",
        "    else:\n",
        "        st.success(\"The model predicts that the patient **does not have diabetes**.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgVkjbjhzyNN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "Welcome To Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
